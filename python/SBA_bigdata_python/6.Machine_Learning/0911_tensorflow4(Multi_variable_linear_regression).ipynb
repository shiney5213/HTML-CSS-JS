{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multi_variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Muli_variable linear regression\n",
    "\n",
    "### prediction exam score\n",
    "\n",
    "- regression using three inputs(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis\n",
    "\n",
    "$$ H(x) = Wx + b $$\n",
    "$$ H(x1, x2, x3) = w1 x1 + w2 x2 + w3 x3 + b $$\n",
    "\n",
    "Cost function\n",
    "\n",
    "$$ H(x1, x2, x3) = w1 x1 + w2 x2 + w3 x3 + b $$\n",
    "$$ cost(W,b) = \\frac{1}{m} \\sum^m_{i=1}(H(x1^{(i)}, x2^{(i)}, x3^{(i)} )-y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_22:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(777)\n",
    "\n",
    "# data set\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y  = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b  = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "\n",
    "hypothesis = x1* w1 + w2 * w1 + x3 * w3 + b\n",
    "print(hypothesis)  #내부적으로 새로운 노드를 연결해서 (추가)해서 학습함\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5d96c8feb64fe49c8d418cb53593a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 9321.1826171875 \n",
      "Prediction :\n",
      "[67.56626 80.09638 78.83894 90.92409 57.1614 ]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 4691.34228515625 \n",
      "Prediction :\n",
      "[ 91.740814 110.52045  108.11304  123.00176   80.503174]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 2363.72412109375 \n",
      "Prediction :\n",
      "[108.881035 132.09189  128.86908  145.74564   97.052986]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1193.4686279296875 \n",
      "Prediction :\n",
      "[121.03423 147.38715 143.58617 161.87218 108.78762]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 605.080078125 \n",
      "Prediction :\n",
      "[129.65161 158.23254 154.02155 173.30692 117.10829]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 309.23968505859375 \n",
      "Prediction :\n",
      "[135.76196 165.92278 161.42104 181.415   123.00832]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 160.4890899658203 \n",
      "Prediction :\n",
      "[140.09468 171.37582 166.66792 187.16429 127.19201]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 85.69593811035156 \n",
      "Prediction :\n",
      "[143.16693 175.24252 170.3884  191.24097 130.15868]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 48.0886344909668 \n",
      "Prediction :\n",
      "[145.34543 177.98438 173.02657 194.13165 132.26237]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 29.1788330078125 \n",
      "Prediction :\n",
      "[146.89015 179.92863 174.89726 196.18138 133.75415]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 9.99243450164795 \n",
      "Prediction :\n",
      "[150.64867 184.67369 179.45743 201.16335 137.40924]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 9.92370319366455 \n",
      "Prediction :\n",
      "[150.64102 184.68028 179.4577  201.14728 137.43044]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 9.855616569519043 \n",
      "Prediction :\n",
      "[150.63339 184.68681 179.45796 201.13126 137.4515 ]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 9.788124084472656 \n",
      "Prediction :\n",
      "[150.6258  184.69333 179.45822 201.1153  137.47249]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 9.721292495727539 \n",
      "Prediction :\n",
      "[150.61823 184.69978 179.45845 201.0994  137.49335]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 9.655128479003906 \n",
      "Prediction :\n",
      "[150.6107  184.7062  179.45871 201.0836  137.51411]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 9.58958625793457 \n",
      "Prediction :\n",
      "[150.6032  184.71263 179.45895 201.06787 137.53477]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 9.524650573730469 \n",
      "Prediction :\n",
      "[150.59578 184.71904 179.45923 201.05226 137.55537]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 9.460338592529297 \n",
      "Prediction :\n",
      "[150.58836 184.72539 179.45949 201.0367  137.57585]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 9.396638870239258 \n",
      "Prediction :\n",
      "[150.58096 184.7317  179.45973 201.0212  137.59622]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 9.333518981933594 \n",
      "Prediction :\n",
      "[150.57362 184.738   179.45999 201.00578 137.61652]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 9.2710599899292 \n",
      "Prediction :\n",
      "[150.5663  184.74428 179.46024 200.99045 137.63669]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 9.2091646194458 \n",
      "Prediction :\n",
      "[150.559   184.7505  179.46046 200.97517 137.65677]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 9.147784233093262 \n",
      "Prediction :\n",
      "[150.55176 184.7567  179.46071 200.95995 137.67676]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 9.087080001831055 \n",
      "Prediction :\n",
      "[150.54453 184.76288 179.46095 200.94482 137.69664]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 9.02688980102539 \n",
      "Prediction :\n",
      "[150.53734 184.76901 179.46118 200.92975 137.71643]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 8.967259407043457 \n",
      "Prediction :\n",
      "[150.5302  184.77515 179.46144 200.91476 137.73615]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 8.908204078674316 \n",
      "Prediction :\n",
      "[150.52309 184.78122 179.46167 200.89984 137.75575]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 8.849756240844727 \n",
      "Prediction :\n",
      "[150.51602 184.78731 179.46194 200.88504 137.77528]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 8.791807174682617 \n",
      "Prediction :\n",
      "[150.50896 184.79332 179.46216 200.87024 137.7947 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val , _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict = {x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-variable matmul linear regression\n",
    "\n",
    "> Hypothesis using matrix\n",
    "$$ w1 x1 + w2 x2 + w3 x3 + ... + wn xn $$\n",
    "\n",
    "$$ [x{1} x{2} x{3}] \\times \\begin{bmatrix} w{1}\\ w{2}\\ w{3}\n",
    "\n",
    "> \\end{bmatrix}\n",
    "[x_1 w_1 + x_2 w_2 + x_3 w_3] $$\n",
    "\n",
    "$$H(X) = XW$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x에 따른 w 변수의 개수를 많이 만들지 않아도 가능\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[73., 80., 75.], \n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.], \n",
    "          [96., 98., 100.], \n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "# 변수의 개수를 여러개 만들지 않아도 가능 -> x, y의 shape맞추어야 함.\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df678a0bb3b34d509051d5711ad03394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 84022.6171875 \n",
      "Prediction :\n",
      "[[ -98.76324 ]\n",
      " [-129.1354  ]\n",
      " [-121.624306]\n",
      " [-134.46591 ]\n",
      " [ -99.58831 ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 26351.775390625 \n",
      "Prediction :\n",
      "[[14.422761]\n",
      " [ 6.909154]\n",
      " [12.420941]\n",
      " [11.506196]\n",
      " [ 4.180112]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 8275.0146484375 \n",
      "Prediction :\n",
      "[[77.79065 ]\n",
      " [83.07608 ]\n",
      " [87.46772 ]\n",
      " [93.23047 ]\n",
      " [62.276962]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 2608.905029296875 \n",
      "Prediction :\n",
      "[[113.26719 ]\n",
      " [125.719666]\n",
      " [129.4834  ]\n",
      " [138.9847  ]\n",
      " [ 94.80397 ]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 832.87158203125 \n",
      "Prediction :\n",
      "[[133.12842]\n",
      " [149.59482]\n",
      " [153.0062 ]\n",
      " [164.60065]\n",
      " [113.01536]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 276.17156982421875 \n",
      "Prediction :\n",
      "[[144.24718]\n",
      " [162.96217]\n",
      " [166.1755 ]\n",
      " [178.9419 ]\n",
      " [123.21197]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 101.66780853271484 \n",
      "Prediction :\n",
      "[[150.47134]\n",
      " [170.44661]\n",
      " [173.54822]\n",
      " [186.97086]\n",
      " [128.92139]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 46.961875915527344 \n",
      "Prediction :\n",
      "[[153.95525]\n",
      " [174.63742]\n",
      " [177.67574]\n",
      " [191.4658 ]\n",
      " [132.11859]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 29.806350708007812 \n",
      "Prediction :\n",
      "[[155.90495]\n",
      " [176.98425]\n",
      " [179.98631]\n",
      " [193.9822 ]\n",
      " [133.90932]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 24.420848846435547 \n",
      "Prediction :\n",
      "[[156.99571]\n",
      " [178.29872]\n",
      " [181.2797 ]\n",
      " [195.39084]\n",
      " [134.9126 ]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 20.921585083007812 \n",
      "Prediction :\n",
      "[[158.22195]\n",
      " [180.08116]\n",
      " [182.87537]\n",
      " [197.14777]\n",
      " [136.33298]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 19.830196380615234 \n",
      "Prediction :\n",
      "[[158.04681]\n",
      " [180.20114]\n",
      " [182.82155]\n",
      " [197.10985]\n",
      " [136.48955]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 18.796367645263672 \n",
      "Prediction :\n",
      "[[157.87636]\n",
      " [180.3179 ]\n",
      " [182.7692 ]\n",
      " [197.07297]\n",
      " [136.64197]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 17.817054748535156 \n",
      "Prediction :\n",
      "[[157.71042]\n",
      " [180.43153]\n",
      " [182.71822]\n",
      " [197.03706]\n",
      " [136.79027]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 16.889392852783203 \n",
      "Prediction :\n",
      "[[157.54892]\n",
      " [180.54216]\n",
      " [182.66861]\n",
      " [197.00218]\n",
      " [136.9346 ]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 16.010663986206055 \n",
      "Prediction :\n",
      "[[157.39174]\n",
      " [180.64983]\n",
      " [182.62032]\n",
      " [196.96825]\n",
      " [137.07507]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 15.178250312805176 \n",
      "Prediction :\n",
      "[[157.23874]\n",
      " [180.75464]\n",
      " [182.5733 ]\n",
      " [196.93523]\n",
      " [137.21176]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 14.389749526977539 \n",
      "Prediction :\n",
      "[[157.0898 ]\n",
      " [180.85661]\n",
      " [182.52754]\n",
      " [196.90309]\n",
      " [137.34479]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 13.642847061157227 \n",
      "Prediction :\n",
      "[[156.94484]\n",
      " [180.95589]\n",
      " [182.48299]\n",
      " [196.87184]\n",
      " [137.47423]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 12.935384750366211 \n",
      "Prediction :\n",
      "[[156.80376]\n",
      " [181.0525 ]\n",
      " [182.43964]\n",
      " [196.84149]\n",
      " [137.6002 ]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 12.26520824432373 \n",
      "Prediction :\n",
      "[[156.66644]\n",
      " [181.14656]\n",
      " [182.39742]\n",
      " [196.81195]\n",
      " [137.7228 ]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 11.630353927612305 \n",
      "Prediction :\n",
      "[[156.53278]\n",
      " [181.23811]\n",
      " [182.35635]\n",
      " [196.7832 ]\n",
      " [137.8421 ]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 11.028950691223145 \n",
      "Prediction :\n",
      "[[156.40265]\n",
      " [181.3272 ]\n",
      " [182.31635]\n",
      " [196.75523]\n",
      " [137.9582 ]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 10.459330558776855 \n",
      "Prediction :\n",
      "[[156.27602]\n",
      " [181.41391]\n",
      " [182.27742]\n",
      " [196.72804]\n",
      " [138.07118]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 9.919754028320312 \n",
      "Prediction :\n",
      "[[156.15276]\n",
      " [181.4983 ]\n",
      " [182.23952]\n",
      " [196.70161]\n",
      " [138.18112]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 9.408622741699219 \n",
      "Prediction :\n",
      "[[156.03278]\n",
      " [181.58044]\n",
      " [182.2026 ]\n",
      " [196.67587]\n",
      " [138.2881 ]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 8.924383163452148 \n",
      "Prediction :\n",
      "[[155.91599]\n",
      " [181.66042]\n",
      " [182.1667 ]\n",
      " [196.65088]\n",
      " [138.39224]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 8.465689659118652 \n",
      "Prediction :\n",
      "[[155.8023 ]\n",
      " [181.73827]\n",
      " [182.13176]\n",
      " [196.62657]\n",
      " [138.49358]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 8.03126335144043 \n",
      "Prediction :\n",
      "[[155.69168]\n",
      " [181.81401]\n",
      " [182.09772]\n",
      " [196.60292]\n",
      " [138.59216]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 7.6196699142456055 \n",
      "Prediction :\n",
      "[[155.58397]\n",
      " [181.88774]\n",
      " [182.06459]\n",
      " [196.57993]\n",
      " [138.68813]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. File input linear regression\n",
    "\n",
    "- Loading data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape : (25, 3), \tlen(x_data) : 25 \n",
      "x_data : \n",
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]\n",
      " [ 69.  74.  77.]\n",
      " [ 47.  56.  60.]\n",
      " [ 87.  79.  90.]\n",
      " [ 79.  70.  88.]\n",
      " [ 69.  70.  73.]\n",
      " [ 70.  65.  74.]\n",
      " [ 93.  95.  91.]\n",
      " [ 79.  80.  73.]\n",
      " [ 70.  73.  78.]\n",
      " [ 93.  89.  96.]\n",
      " [ 78.  75.  68.]\n",
      " [ 81.  90.  93.]\n",
      " [ 88.  92.  86.]\n",
      " [ 78.  83.  77.]\n",
      " [ 82.  86.  90.]\n",
      " [ 86.  82.  89.]\n",
      " [ 78.  83.  85.]\n",
      " [ 76.  83.  71.]\n",
      " [ 96.  93.  95.]]\n",
      "-------------------------\n",
      "y_data.shape : (25, 1)  \n",
      "y_data : \n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]\n",
      " [149.]\n",
      " [115.]\n",
      " [175.]\n",
      " [164.]\n",
      " [141.]\n",
      " [141.]\n",
      " [184.]\n",
      " [152.]\n",
      " [148.]\n",
      " [192.]\n",
      " [147.]\n",
      " [183.]\n",
      " [177.]\n",
      " [159.]\n",
      " [177.]\n",
      " [175.]\n",
      " [175.]\n",
      " [149.]\n",
      " [192.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "xy = np.loadtxt('data/data-01-test-score.csv', delimiter = ',', dtype = np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(\"x_data.shape : {}, \\tlen(x_data) : {} \\nx_data : \\n{}\".format(x_data.shape, len(x_data), x_data))\n",
    "print(\"-\"*25)\n",
    "print(\"y_data.shape : {}  \\ny_data : \\n{}\".format(y_data.shape, y_data))\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 24700.72265625 \n",
      "Prediction :\n",
      "[[ 1.2699044]\n",
      " [10.017089 ]\n",
      " [ 5.3647304]\n",
      " [ 7.6310306]\n",
      " [ 8.236796 ]\n",
      " [ 9.749408 ]\n",
      " [ 5.930961 ]\n",
      " [ 4.46919  ]\n",
      " [13.477244 ]\n",
      " [17.144417 ]\n",
      " [ 6.408031 ]\n",
      " [10.726584 ]\n",
      " [ 3.8850625]\n",
      " [ 1.2374375]\n",
      " [ 7.418155 ]\n",
      " [11.074962 ]\n",
      " [ 1.6429932]\n",
      " [ 6.3120456]\n",
      " [ 2.1118195]\n",
      " [ 1.277427 ]\n",
      " [ 7.5684657]\n",
      " [10.57437  ]\n",
      " [ 5.9860034]\n",
      " [-2.6355674]\n",
      " [ 8.22737  ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 9142.439453125 \n",
      "Prediction :\n",
      "[[59.17228 ]\n",
      " [79.60789 ]\n",
      " [73.935005]\n",
      " [82.308876]\n",
      " [61.310806]\n",
      " [48.877823]\n",
      " [61.83008 ]\n",
      " [45.909664]\n",
      " [78.51375 ]\n",
      " [77.38296 ]\n",
      " [60.263588]\n",
      " [63.828033]\n",
      " [74.72799 ]\n",
      " [60.129032]\n",
      " [63.5738  ]\n",
      " [81.69312 ]\n",
      " [57.729187]\n",
      " [73.3968  ]\n",
      " [69.65087 ]\n",
      " [61.70898 ]\n",
      " [73.11883 ]\n",
      " [75.85966 ]\n",
      " [68.48344 ]\n",
      " [55.744686]\n",
      " [80.35076 ]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 3390.1083984375 \n",
      "Prediction :\n",
      "[[ 94.380516]\n",
      " [121.92238 ]\n",
      " [115.62951 ]\n",
      " [127.717   ]\n",
      " [ 93.58216 ]\n",
      " [ 72.66932 ]\n",
      " [ 95.81983 ]\n",
      " [ 71.10793 ]\n",
      " [118.05862 ]\n",
      " [114.01011 ]\n",
      " [ 93.01057 ]\n",
      " [ 96.115974]\n",
      " [117.8045  ]\n",
      " [ 95.93857 ]\n",
      " [ 97.71937 ]\n",
      " [124.63227 ]\n",
      " [ 91.83271 ]\n",
      " [114.18819 ]\n",
      " [110.71861 ]\n",
      " [ 98.45504 ]\n",
      " [112.97697 ]\n",
      " [115.556145]\n",
      " [106.485344]\n",
      " [ 91.24376 ]\n",
      " [124.205414]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1263.307373046875 \n",
      "Prediction :\n",
      "[[115.78953 ]\n",
      " [147.65144 ]\n",
      " [140.98215 ]\n",
      " [155.3276  ]\n",
      " [113.204414]\n",
      " [ 87.13517 ]\n",
      " [116.48754 ]\n",
      " [ 86.43009 ]\n",
      " [142.10324 ]\n",
      " [136.2803  ]\n",
      " [112.92242 ]\n",
      " [115.748215]\n",
      " [143.99759 ]\n",
      " [117.713   ]\n",
      " [118.48165 ]\n",
      " [150.74115 ]\n",
      " [112.5696  ]\n",
      " [138.99184 ]\n",
      " [135.69043 ]\n",
      " [120.799065]\n",
      " [137.21289 ]\n",
      " [139.6933  ]\n",
      " [129.59271 ]\n",
      " [112.82987 ]\n",
      " [150.87119 ]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 476.9667663574219 \n",
      "Prediction :\n",
      "[[128.80788 ]\n",
      " [163.2957  ]\n",
      " [156.39804 ]\n",
      " [172.11635 ]\n",
      " [125.13534 ]\n",
      " [ 95.93054 ]\n",
      " [129.05475 ]\n",
      " [ 95.74705 ]\n",
      " [156.7229  ]\n",
      " [149.82068 ]\n",
      " [125.02983 ]\n",
      " [127.685104]\n",
      " [159.92464 ]\n",
      " [130.95335 ]\n",
      " [131.10619 ]\n",
      " [166.61629 ]\n",
      " [125.178894]\n",
      " [154.07408 ]\n",
      " [150.87503 ]\n",
      " [134.38591 ]\n",
      " [151.94966 ]\n",
      " [154.36954 ]\n",
      " [143.64339 ]\n",
      " [125.956184]\n",
      " [167.0852  ]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 186.2300567626953 \n",
      "Prediction :\n",
      "[[136.72426]\n",
      " [172.80788]\n",
      " [165.77191]\n",
      " [182.32487]\n",
      " [132.38954]\n",
      " [101.27797]\n",
      " [136.69643]\n",
      " [101.41254]\n",
      " [165.61171]\n",
      " [158.05292]\n",
      " [132.39175]\n",
      " [134.94286]\n",
      " [169.60942]\n",
      " [139.00453]\n",
      " [138.78258]\n",
      " [176.26884]\n",
      " [132.84619]\n",
      " [163.24525]\n",
      " [160.10855]\n",
      " [142.64792]\n",
      " [160.9105 ]\n",
      " [163.29309]\n",
      " [152.18713]\n",
      " [133.93849]\n",
      " [176.94405]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 78.7322998046875 \n",
      "Prediction :\n",
      "[[141.5384  ]\n",
      " [178.59143 ]\n",
      " [171.47191 ]\n",
      " [188.53229 ]\n",
      " [136.80006 ]\n",
      " [104.528854]\n",
      " [141.34314 ]\n",
      " [104.85775 ]\n",
      " [171.01585 ]\n",
      " [163.05751 ]\n",
      " [136.86818 ]\n",
      " [139.35542 ]\n",
      " [175.4986  ]\n",
      " [143.90045 ]\n",
      " [143.45021 ]\n",
      " [182.13773 ]\n",
      " [137.50848 ]\n",
      " [168.82214 ]\n",
      " [165.7235  ]\n",
      " [147.67218 ]\n",
      " [166.35924 ]\n",
      " [168.71867 ]\n",
      " [157.3824  ]\n",
      " [138.79297 ]\n",
      " [182.93858 ]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 38.983238220214844 \n",
      "Prediction :\n",
      "[[144.4662  ]\n",
      " [182.10776 ]\n",
      " [174.93799 ]\n",
      " [192.30676 ]\n",
      " [139.48148 ]\n",
      " [106.50493 ]\n",
      " [144.16873 ]\n",
      " [106.952896]\n",
      " [174.30112 ]\n",
      " [166.09952 ]\n",
      " [139.59004 ]\n",
      " [142.03796 ]\n",
      " [179.0798  ]\n",
      " [146.87778 ]\n",
      " [146.28836 ]\n",
      " [185.7059  ]\n",
      " [140.34358 ]\n",
      " [172.21353 ]\n",
      " [169.13812 ]\n",
      " [150.72769 ]\n",
      " [169.67244 ]\n",
      " [172.01733 ]\n",
      " [160.5416  ]\n",
      " [141.74557 ]\n",
      " [186.58342 ]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 24.282676696777344 \n",
      "Prediction :\n",
      "[[146.24701 ]\n",
      " [184.24551 ]\n",
      " [177.04572 ]\n",
      " [194.60193 ]\n",
      " [141.11147 ]\n",
      " [107.705864]\n",
      " [145.887   ]\n",
      " [108.22714 ]\n",
      " [176.298   ]\n",
      " [167.94818 ]\n",
      " [141.24506 ]\n",
      " [143.66856 ]\n",
      " [181.25768 ]\n",
      " [148.6885  ]\n",
      " [148.0141  ]\n",
      " [187.87515 ]\n",
      " [142.06764 ]\n",
      " [174.27603 ]\n",
      " [171.21484 ]\n",
      " [152.58609 ]\n",
      " [171.68712 ]\n",
      " [174.02269 ]\n",
      " [162.46274 ]\n",
      " [143.54172 ]\n",
      " [188.79953 ]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 18.843168258666992 \n",
      "Prediction :\n",
      "[[147.3304 ]\n",
      " [185.54504]\n",
      " [178.32751]\n",
      " [195.99759]\n",
      " [142.10217]\n",
      " [108.43547]\n",
      " [146.93195]\n",
      " [109.00226]\n",
      " [177.5115 ]\n",
      " [169.07123]\n",
      " [142.25137]\n",
      " [144.65955]\n",
      " [182.58224]\n",
      " [149.78989]\n",
      " [149.06345]\n",
      " [189.1938 ]\n",
      " [143.11613]\n",
      " [175.53049]\n",
      " [172.47809]\n",
      " [153.71661]\n",
      " [172.91223]\n",
      " [175.24167]\n",
      " [163.6311 ]\n",
      " [144.6347 ]\n",
      " [190.14688]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 15.062270164489746 \n",
      "Prediction :\n",
      "[[149.13525 ]\n",
      " [187.48073 ]\n",
      " [180.35748 ]\n",
      " [198.18004 ]\n",
      " [143.54376 ]\n",
      " [109.42724 ]\n",
      " [148.58896 ]\n",
      " [110.270256]\n",
      " [179.23169 ]\n",
      " [170.581   ]\n",
      " [143.80728 ]\n",
      " [146.07974 ]\n",
      " [184.70427 ]\n",
      " [151.57857 ]\n",
      " [150.69003 ]\n",
      " [191.15268 ]\n",
      " [144.7815  ]\n",
      " [177.55534 ]\n",
      " [174.54163 ]\n",
      " [155.5831  ]\n",
      " [174.83191 ]\n",
      " [177.04492 ]\n",
      " [165.48923 ]\n",
      " [146.51357 ]\n",
      " [192.20294 ]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 14.454951286315918 \n",
      "Prediction :\n",
      "[[149.26907 ]\n",
      " [187.39375 ]\n",
      " [180.40195 ]\n",
      " [198.19888 ]\n",
      " [143.44022 ]\n",
      " [109.276245]\n",
      " [148.62859 ]\n",
      " [110.342674]\n",
      " [179.05676 ]\n",
      " [170.33139 ]\n",
      " [143.80194 ]\n",
      " [145.95378 ]\n",
      " [184.776   ]\n",
      " [151.66364 ]\n",
      " [150.68956 ]\n",
      " [191.05916 ]\n",
      " [144.82146 ]\n",
      " [177.64172 ]\n",
      " [174.65286 ]\n",
      " [155.7041  ]\n",
      " [174.85335 ]\n",
      " [176.95038 ]\n",
      " [165.5391  ]\n",
      " [146.71008 ]\n",
      " [192.16559 ]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 13.89159870147705 \n",
      "Prediction :\n",
      "[[149.39786]\n",
      " [187.3096 ]\n",
      " [180.44449]\n",
      " [198.21716]\n",
      " [143.33977]\n",
      " [109.131  ]\n",
      " [148.66763]\n",
      " [110.41416]\n",
      " [178.88846]\n",
      " [170.09218]\n",
      " [143.79712]\n",
      " [145.83284]\n",
      " [184.8443 ]\n",
      " [151.74422]\n",
      " [150.69   ]\n",
      " [190.9692 ]\n",
      " [144.858  ]\n",
      " [177.72635]\n",
      " [174.7592 ]\n",
      " [155.82002]\n",
      " [174.87485]\n",
      " [176.85942]\n",
      " [165.5878 ]\n",
      " [146.8981 ]\n",
      " [192.129  ]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 13.368897438049316 \n",
      "Prediction :\n",
      "[[149.52179]\n",
      " [187.22824]\n",
      " [180.48518]\n",
      " [198.23495]\n",
      " [143.24231]\n",
      " [108.99127]\n",
      " [148.70613]\n",
      " [110.48471]\n",
      " [178.72656]\n",
      " [169.86296]\n",
      " [143.79277]\n",
      " [145.71674]\n",
      " [184.90933]\n",
      " [151.82053]\n",
      " [150.69133]\n",
      " [190.88263]\n",
      " [144.89136]\n",
      " [177.80923]\n",
      " [174.86089]\n",
      " [155.93112]\n",
      " [174.89636]\n",
      " [176.77197]\n",
      " [165.6354 ]\n",
      " [147.07799]\n",
      " [192.09325]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 12.883708953857422 \n",
      "Prediction :\n",
      "[[149.64107]\n",
      " [187.1495 ]\n",
      " [180.52412]\n",
      " [198.25226]\n",
      " [143.14777]\n",
      " [108.85684]\n",
      " [148.74405]\n",
      " [110.55431]\n",
      " [178.57077]\n",
      " [169.64328]\n",
      " [143.78886]\n",
      " [145.60526]\n",
      " [184.97124]\n",
      " [151.89279]\n",
      " [150.69348]\n",
      " [190.79938]\n",
      " [144.92168]\n",
      " [177.89041]\n",
      " [174.9581 ]\n",
      " [156.03758]\n",
      " [174.91791]\n",
      " [176.68787]\n",
      " [165.6819 ]\n",
      " [147.25009]\n",
      " [192.05827]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 12.433196067810059 \n",
      "Prediction :\n",
      "[[149.75587]\n",
      " [187.07335]\n",
      " [180.56139]\n",
      " [198.26909]\n",
      " [143.05602]\n",
      " [108.72747]\n",
      " [148.7814 ]\n",
      " [110.62292]\n",
      " [178.42085]\n",
      " [169.43275]\n",
      " [143.7854 ]\n",
      " [145.49821]\n",
      " [185.03017]\n",
      " [151.9612 ]\n",
      " [150.69637]\n",
      " [190.71927]\n",
      " [144.94914]\n",
      " [177.96992]\n",
      " [175.05104]\n",
      " [156.13962]\n",
      " [174.9394 ]\n",
      " [176.60696]\n",
      " [165.72731]\n",
      " [147.41475]\n",
      " [192.02408]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 12.014721870422363 \n",
      "Prediction :\n",
      "[[149.86638]\n",
      " [186.99965]\n",
      " [180.59706]\n",
      " [198.28548]\n",
      " [142.967  ]\n",
      " [108.60301]\n",
      " [148.81818]\n",
      " [110.69058]\n",
      " [178.27661]\n",
      " [169.231  ]\n",
      " [143.78232]\n",
      " [145.39543]\n",
      " [185.08629]\n",
      " [152.02591]\n",
      " [150.69998]\n",
      " [190.6422 ]\n",
      " [144.97392]\n",
      " [178.04778]\n",
      " [175.13991]\n",
      " [156.23741]\n",
      " [174.9609 ]\n",
      " [176.52916]\n",
      " [165.77171]\n",
      " [147.5723 ]\n",
      " [191.99065]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 11.625877380371094 \n",
      "Prediction :\n",
      "[[149.97276 ]\n",
      " [186.92834 ]\n",
      " [180.63121 ]\n",
      " [198.30139 ]\n",
      " [142.88063 ]\n",
      " [108.48322 ]\n",
      " [148.85437 ]\n",
      " [110.757256]\n",
      " [178.1378  ]\n",
      " [169.03763 ]\n",
      " [143.77963 ]\n",
      " [145.29674 ]\n",
      " [185.13971 ]\n",
      " [152.08714 ]\n",
      " [150.70422 ]\n",
      " [190.56802 ]\n",
      " [144.99615 ]\n",
      " [178.12402 ]\n",
      " [175.22487 ]\n",
      " [156.33112 ]\n",
      " [174.98235 ]\n",
      " [176.45432 ]\n",
      " [165.81506 ]\n",
      " [147.72305 ]\n",
      " [191.95798 ]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 11.264404296875 \n",
      "Prediction :\n",
      "[[150.0752  ]\n",
      " [186.85934 ]\n",
      " [180.66386 ]\n",
      " [198.31686 ]\n",
      " [142.79678 ]\n",
      " [108.36795 ]\n",
      " [148.88998 ]\n",
      " [110.822945]\n",
      " [178.00418 ]\n",
      " [168.85226 ]\n",
      " [143.77728 ]\n",
      " [145.20193 ]\n",
      " [185.19052 ]\n",
      " [152.14502 ]\n",
      " [150.70908 ]\n",
      " [190.49663 ]\n",
      " [145.01599 ]\n",
      " [178.19867 ]\n",
      " [175.30608 ]\n",
      " [156.42093 ]\n",
      " [175.0037  ]\n",
      " [176.3823  ]\n",
      " [165.85742 ]\n",
      " [147.86726 ]\n",
      " [191.926   ]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 10.928301811218262 \n",
      "Prediction :\n",
      "[[150.17381 ]\n",
      " [186.79256 ]\n",
      " [180.69514 ]\n",
      " [198.33194 ]\n",
      " [142.71544 ]\n",
      " [108.25699 ]\n",
      " [148.92503 ]\n",
      " [110.887634]\n",
      " [177.87558 ]\n",
      " [168.6746  ]\n",
      " [143.77528 ]\n",
      " [145.1109  ]\n",
      " [185.23888 ]\n",
      " [152.19974 ]\n",
      " [150.71452 ]\n",
      " [190.42793 ]\n",
      " [145.03358 ]\n",
      " [178.27174 ]\n",
      " [175.38374 ]\n",
      " [156.50703 ]\n",
      " [175.02495 ]\n",
      " [176.31303 ]\n",
      " [165.89879 ]\n",
      " [148.00526 ]\n",
      " [191.89476 ]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 10.615635871887207 \n",
      "Prediction :\n",
      "[[150.26877]\n",
      " [186.72792]\n",
      " [180.72505]\n",
      " [198.3466 ]\n",
      " [142.63647]\n",
      " [108.15019]\n",
      " [148.9595 ]\n",
      " [110.95134]\n",
      " [177.75179]\n",
      " [168.50433]\n",
      " [143.77359]\n",
      " [145.02347]\n",
      " [185.28491]\n",
      " [152.25143]\n",
      " [150.72046]\n",
      " [190.36182]\n",
      " [145.04904]\n",
      " [178.34329]\n",
      " [175.45798]\n",
      " [156.58957]\n",
      " [175.04611]\n",
      " [176.24638]\n",
      " [165.93921]\n",
      " [148.1373 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [191.86423]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 10.324675559997559 \n",
      "Prediction :\n",
      "[[150.36023]\n",
      " [186.66536]\n",
      " [180.7537 ]\n",
      " [198.36087]\n",
      " [142.5598 ]\n",
      " [108.04738]\n",
      " [148.99341]\n",
      " [111.01404]\n",
      " [177.63261]\n",
      " [168.34111]\n",
      " [143.7722 ]\n",
      " [144.9395 ]\n",
      " [185.32869]\n",
      " [152.30028]\n",
      " [150.72687]\n",
      " [190.29816]\n",
      " [145.06252]\n",
      " [178.41331]\n",
      " [175.52898]\n",
      " [156.66869]\n",
      " [175.06712]\n",
      " [176.18224]\n",
      " [165.9787 ]\n",
      " [148.26364]\n",
      " [191.83437]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 10.053807258605957 \n",
      "Prediction :\n",
      "[[150.44829 ]\n",
      " [186.60478 ]\n",
      " [180.7811  ]\n",
      " [198.37476 ]\n",
      " [142.4854  ]\n",
      " [107.94838 ]\n",
      " [149.02673 ]\n",
      " [111.075745]\n",
      " [177.51787 ]\n",
      " [168.18463 ]\n",
      " [143.77109 ]\n",
      " [144.85881 ]\n",
      " [185.37032 ]\n",
      " [152.34637 ]\n",
      " [150.73372 ]\n",
      " [190.23688 ]\n",
      " [145.07413 ]\n",
      " [178.48186 ]\n",
      " [175.59683 ]\n",
      " [156.7445  ]\n",
      " [175.08801 ]\n",
      " [176.12051 ]\n",
      " [166.01724 ]\n",
      " [148.3845  ]\n",
      " [191.8052  ]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 9.801552772521973 \n",
      "Prediction :\n",
      "[[150.53311]\n",
      " [186.54613]\n",
      " [180.80733]\n",
      " [198.38824]\n",
      " [142.41313]\n",
      " [107.85307]\n",
      " [149.05948]\n",
      " [111.13645]\n",
      " [177.40738]\n",
      " [168.03462]\n",
      " [143.77022]\n",
      " [144.78131]\n",
      " [185.4099 ]\n",
      " [152.38988]\n",
      " [150.74097]\n",
      " [190.17787]\n",
      " [145.08394]\n",
      " [178.54893]\n",
      " [175.6617 ]\n",
      " [156.81718]\n",
      " [175.10875]\n",
      " [176.0611 ]\n",
      " [166.0549 ]\n",
      " [148.50015]\n",
      " [191.77666]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 9.566553115844727 \n",
      "Prediction :\n",
      "[[150.61482]\n",
      " [186.48935]\n",
      " [180.83241]\n",
      " [198.40137]\n",
      " [142.343  ]\n",
      " [107.76131]\n",
      " [149.09166]\n",
      " [111.19616]\n",
      " [177.301  ]\n",
      " [167.89081]\n",
      " [143.76959]\n",
      " [144.70685]\n",
      " [185.44754]\n",
      " [152.43092]\n",
      " [150.74857]\n",
      " [190.12106]\n",
      " [145.09212]\n",
      " [178.61456]\n",
      " [175.7237 ]\n",
      " [156.88687]\n",
      " [175.1293 ]\n",
      " [176.0039 ]\n",
      " [166.09167]\n",
      " [148.61081]\n",
      " [191.74878]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 9.347516059875488 \n",
      "Prediction :\n",
      "[[150.69356]\n",
      " [186.43437]\n",
      " [180.85645]\n",
      " [198.41415]\n",
      " [142.2749 ]\n",
      " [107.67293]\n",
      " [149.1233 ]\n",
      " [111.25489]\n",
      " [177.19855]\n",
      " [167.75296]\n",
      " [143.76921]\n",
      " [144.63531]\n",
      " [185.48337]\n",
      " [152.46964]\n",
      " [150.75653]\n",
      " [190.06638]\n",
      " [145.09875]\n",
      " [178.6788 ]\n",
      " [175.783  ]\n",
      " [156.95367]\n",
      " [175.14972]\n",
      " [175.9489 ]\n",
      " [166.12762]\n",
      " [148.7167 ]\n",
      " [191.72156]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 9.143309593200684 \n",
      "Prediction :\n",
      "[[150.7694 ]\n",
      " [186.38113]\n",
      " [180.87944]\n",
      " [198.42662]\n",
      " [142.20879]\n",
      " [107.58783]\n",
      " [149.15437]\n",
      " [111.31264]\n",
      " [177.09988]\n",
      " [167.62077]\n",
      " [143.76903]\n",
      " [144.56657]\n",
      " [185.5174 ]\n",
      " [152.5061 ]\n",
      " [150.76479]\n",
      " [190.01372]\n",
      " [145.10393]\n",
      " [178.74167]\n",
      " [175.83969]\n",
      " [157.01775]\n",
      " [175.16994]\n",
      " [175.89592]\n",
      " [166.1627 ]\n",
      " [148.81804]\n",
      " [191.69493]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 8.952862739562988 \n",
      "Prediction :\n",
      "[[150.84245 ]\n",
      " [186.32954 ]\n",
      " [180.90144 ]\n",
      " [198.4387  ]\n",
      " [142.14456 ]\n",
      " [107.505844]\n",
      " [149.18489 ]\n",
      " [111.36937 ]\n",
      " [177.00484 ]\n",
      " [167.49403 ]\n",
      " [143.76904 ]\n",
      " [144.50052 ]\n",
      " [185.54973 ]\n",
      " [152.54042 ]\n",
      " [150.7733  ]\n",
      " [189.96297 ]\n",
      " [145.10771 ]\n",
      " [178.80315 ]\n",
      " [175.89384 ]\n",
      " [157.07913 ]\n",
      " [175.18993 ]\n",
      " [175.8449  ]\n",
      " [166.19696 ]\n",
      " [148.91496 ]\n",
      " [191.6689  ]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 8.775155067443848 \n",
      "Prediction :\n",
      "[[150.91287 ]\n",
      " [186.27962 ]\n",
      " [180.92252 ]\n",
      " [198.4505  ]\n",
      " [142.0822  ]\n",
      " [107.426895]\n",
      " [149.21487 ]\n",
      " [111.425156]\n",
      " [176.9133  ]\n",
      " [167.37253 ]\n",
      " [143.76926 ]\n",
      " [144.43706 ]\n",
      " [185.58047 ]\n",
      " [152.57278 ]\n",
      " [150.78207 ]\n",
      " [189.91412 ]\n",
      " [145.11026 ]\n",
      " [178.86331 ]\n",
      " [175.94565 ]\n",
      " [157.13803 ]\n",
      " [175.20975 ]\n",
      " [175.7958  ]\n",
      " [166.23044 ]\n",
      " [149.00772 ]\n",
      " [191.64348 ]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 8.609268188476562 \n",
      "Prediction :\n",
      "[[150.98073]\n",
      " [186.23123]\n",
      " [180.94269]\n",
      " [198.46196]\n",
      " [142.02164]\n",
      " [107.35083]\n",
      " [149.2443 ]\n",
      " [111.47996]\n",
      " [176.82512]\n",
      " [167.25603]\n",
      " [143.76962]\n",
      " [144.37605]\n",
      " [185.60968]\n",
      " [152.60318]\n",
      " [150.79105]\n",
      " [189.86707]\n",
      " [145.1116 ]\n",
      " [178.92216]\n",
      " [175.99518]\n",
      " [157.19449]\n",
      " [175.22937]\n",
      " [175.74852]\n",
      " [166.26312]\n",
      " [149.09648]\n",
      " [191.61865]]\n"
     ]
    }
   ],
   "source": [
    "#Lunch the graphh  in a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict ={X: x_data, Y: y_data})\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b151a633fce48de84ac719a46d3bff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 \tCost : 8.607675552368164 \n",
      "Step : 1 \tCost : 8.60608196258545 \n",
      "Step : 2 \tCost : 8.604462623596191 \n",
      "Step : 3 \tCost : 8.602865219116211 \n",
      "Step : 4 \tCost : 8.601276397705078 \n",
      "Step : 5 \tCost : 8.599686622619629 \n",
      "Step : 6 \tCost : 8.598084449768066 \n",
      "Step : 7 \tCost : 8.596487045288086 \n",
      "Step : 8 \tCost : 8.594901084899902 \n",
      "Step : 9 \tCost : 8.593306541442871 \n",
      "Step : 100 \tCost : 8.452879905700684 \n",
      "Step : 200 \tCost : 8.308319091796875 \n",
      "Step : 300 \tCost : 8.173196792602539 \n",
      "Step : 400 \tCost : 8.04690170288086 \n",
      "Step : 500 \tCost : 7.928780555725098 \n",
      "Step : 600 \tCost : 7.818299770355225 \n",
      "Step : 700 \tCost : 7.714881420135498 \n",
      "Step : 800 \tCost : 7.6180500984191895 \n",
      "Step : 900 \tCost : 7.527389049530029 \n",
      "Step : 1000 \tCost : 7.442434787750244 \n",
      "Step : 1100 \tCost : 7.362819671630859 \n",
      "Step : 1200 \tCost : 7.2881693840026855 \n",
      "Step : 1300 \tCost : 7.218160629272461 \n",
      "Step : 1400 \tCost : 7.152468681335449 \n",
      "Step : 1500 \tCost : 7.090813159942627 \n",
      "Step : 1600 \tCost : 7.032930850982666 \n",
      "Step : 1700 \tCost : 6.978568077087402 \n",
      "Step : 1800 \tCost : 6.927484512329102 \n",
      "Step : 1900 \tCost : 6.87948751449585 \n",
      "Step : 2000 \tCost : 6.834366321563721 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "# sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "# sess.run(tf.global_variables_initializer())# 변수 초기화 안하면-> 4000번 학습 한 결과가 됨.\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        # print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "        print(\"Step : {} \\tCost : {} \".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[191.2904]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score\n",
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other scores \t: \n",
      " [[179.8336 ]\n",
      " [174.10446]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score many\n",
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex04. TF reader linear regression 5¶\n",
    "\n",
    "참조 : https://www.tensorflow.org/programmers_guide/reading_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 11:02:54.187481  2396 deprecation.py:323] From <ipython-input-37-80cf1f25dbb8>:6: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0911 11:02:54.199203  2396 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0911 11:02:54.202131  2396 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W0911 11:02:54.208968  2396 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0911 11:02:54.212874  2396 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0911 11:02:54.220688  2396 deprecation.py:323] From <ipython-input-37-80cf1f25dbb8>:8: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "W0911 11:02:54.231432  2396 deprecation.py:323] From <ipython-input-37-80cf1f25dbb8>:18: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['./data/data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader() \n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the decoded result.\n",
    "# Convert CSV records to tensors. Each column maps to one tensor.\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults) # 데이터를 텐서 형태로 변환\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414ec9bf7f0b456094dddfdfb6c909bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 341.5231018066406 \n",
      "Prediction :\n",
      "[[143.32368]\n",
      " [166.74939]\n",
      " [167.34601]\n",
      " [179.39067]\n",
      " [128.23233]\n",
      " [ 89.61351]\n",
      " [131.67331]\n",
      " [ 94.10205]\n",
      " [151.13309]\n",
      " [133.25743]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 100.0609130859375 \n",
      "Prediction :\n",
      "[[133.89035]\n",
      " [128.53712]\n",
      " [183.22253]\n",
      " [156.05069]\n",
      " [137.12808]\n",
      " [174.5272 ]\n",
      " [150.38373]\n",
      " [164.56947]\n",
      " [175.9792 ]\n",
      " [157.56711]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 88.00960540771484 \n",
      "Prediction :\n",
      "[[164.2063 ]\n",
      " [163.62335]\n",
      " [157.84053]\n",
      " [159.60732]\n",
      " [185.58348]\n",
      " [151.81682]\n",
      " [176.96762]\n",
      " [177.40858]\n",
      " [190.35352]\n",
      " [136.02472]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 96.20046997070312 \n",
      "Prediction :\n",
      "[[ 96.978676]\n",
      " [142.18433 ]\n",
      " [101.898865]\n",
      " [163.3698  ]\n",
      " [144.6033  ]\n",
      " [138.28401 ]\n",
      " [132.87167 ]\n",
      " [188.9967  ]\n",
      " [160.84795 ]\n",
      " [141.71132 ]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 86.31586456298828 \n",
      "Prediction :\n",
      "[[182.52696]\n",
      " [156.71867]\n",
      " [172.16983]\n",
      " [183.6151 ]\n",
      " [164.3992 ]\n",
      " [168.98267]\n",
      " [168.38185]\n",
      " [162.39276]\n",
      " [163.8454 ]\n",
      " [190.83456]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 55.44389724731445 \n",
      "Prediction :\n",
      "[[156.64783 ]\n",
      " [182.78555 ]\n",
      " [183.13472 ]\n",
      " [196.5949  ]\n",
      " [140.4604  ]\n",
      " [ 98.645386]\n",
      " [144.5587  ]\n",
      " [103.66424 ]\n",
      " [166.13618 ]\n",
      " [147.17603 ]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 67.06041717529297 \n",
      "Prediction :\n",
      "[[141.74365]\n",
      " [136.2912 ]\n",
      " [193.53268]\n",
      " [164.6113 ]\n",
      " [145.32333]\n",
      " [184.82835]\n",
      " [158.5323 ]\n",
      " [174.35654]\n",
      " [185.80455]\n",
      " [166.35805]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 50.541358947753906 \n",
      "Prediction :\n",
      "[[169.99818]\n",
      " [169.39336]\n",
      " [163.35857]\n",
      " [164.72466]\n",
      " [191.94287]\n",
      " [156.91185]\n",
      " [183.11055]\n",
      " [183.45071]\n",
      " [196.94241]\n",
      " [140.7074 ]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 73.27690124511719 \n",
      "Prediction :\n",
      "[[ 98.935875]\n",
      " [144.96536 ]\n",
      " [103.97043 ]\n",
      " [166.61472 ]\n",
      " [147.63    ]\n",
      " [140.96027 ]\n",
      " [135.52254 ]\n",
      " [192.49475 ]\n",
      " [163.74466 ]\n",
      " [144.50902 ]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 83.74688720703125 \n",
      "Prediction :\n",
      "[[184.89268]\n",
      " [158.56262]\n",
      " [174.41837]\n",
      " [185.84914]\n",
      " [166.39766]\n",
      " [171.17851]\n",
      " [170.57013]\n",
      " [164.48233]\n",
      " [165.7606 ]\n",
      " [193.23732]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 44.38762283325195 \n",
      "Prediction :\n",
      "[[157.61626 ]\n",
      " [184.30495 ]\n",
      " [184.43555 ]\n",
      " [198.17111 ]\n",
      " [141.57594 ]\n",
      " [ 99.75552 ]\n",
      " [145.87608 ]\n",
      " [104.822624]\n",
      " [167.83356 ]\n",
      " [149.13263 ]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 40.671348571777344 \n",
      "Prediction :\n",
      "[[157.39055]\n",
      " [184.38878]\n",
      " [184.32193]\n",
      " [198.2083 ]\n",
      " [141.59537]\n",
      " [100.05968]\n",
      " [146.04364]\n",
      " [105.13165]\n",
      " [168.19092]\n",
      " [149.85114]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 37.2939453125 \n",
      "Prediction :\n",
      "[[157.17592]\n",
      " [184.46756]\n",
      " [184.21336]\n",
      " [198.24416]\n",
      " [141.612  ]\n",
      " [100.3491 ]\n",
      " [146.20523]\n",
      " [105.42984]\n",
      " [168.53094]\n",
      " [150.53688]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 34.22462844848633 \n",
      "Prediction :\n",
      "[[156.97186 ]\n",
      " [184.54158 ]\n",
      " [184.10966 ]\n",
      " [198.27881 ]\n",
      " [141.626   ]\n",
      " [100.624504]\n",
      " [146.36108 ]\n",
      " [105.717606]\n",
      " [168.85454 ]\n",
      " [151.1914  ]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 31.435733795166016 \n",
      "Prediction :\n",
      "[[156.77786 ]\n",
      " [184.61102 ]\n",
      " [184.01054 ]\n",
      " [198.31221 ]\n",
      " [141.63756 ]\n",
      " [100.88651 ]\n",
      " [146.51143 ]\n",
      " [105.995316]\n",
      " [169.16237 ]\n",
      " [151.81609 ]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 28.901897430419922 \n",
      "Prediction :\n",
      "[[156.59346 ]\n",
      " [184.67618 ]\n",
      " [183.91585 ]\n",
      " [198.34447 ]\n",
      " [141.64682 ]\n",
      " [101.13577 ]\n",
      " [146.65648 ]\n",
      " [106.263374]\n",
      " [169.45522 ]\n",
      " [152.41228 ]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 26.6000919342041 \n",
      "Prediction :\n",
      "[[156.41818 ]\n",
      " [184.73723 ]\n",
      " [183.82532 ]\n",
      " [198.37555 ]\n",
      " [141.6539  ]\n",
      " [101.372856]\n",
      " [146.79639 ]\n",
      " [106.522125]\n",
      " [169.73376 ]\n",
      " [152.98125 ]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 24.509355545043945 \n",
      "Prediction :\n",
      "[[156.25162]\n",
      " [184.79442]\n",
      " [183.73886]\n",
      " [198.4056 ]\n",
      " [141.659  ]\n",
      " [101.59837]\n",
      " [146.93141]\n",
      " [106.77195]\n",
      " [169.99869]\n",
      " [153.52423]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 22.610509872436523 \n",
      "Prediction :\n",
      "[[156.09337 ]\n",
      " [184.84792 ]\n",
      " [183.6562  ]\n",
      " [198.43457 ]\n",
      " [141.6622  ]\n",
      " [101.81283 ]\n",
      " [147.06169 ]\n",
      " [107.013145]\n",
      " [170.25063 ]\n",
      " [154.04243 ]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 20.886249542236328 \n",
      "Prediction :\n",
      "[[155.94301 ]\n",
      " [184.89793 ]\n",
      " [183.57726 ]\n",
      " [198.46257 ]\n",
      " [141.66364 ]\n",
      " [102.01675 ]\n",
      " [147.18745 ]\n",
      " [107.246056]\n",
      " [170.49019 ]\n",
      " [154.53694 ]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 19.3206787109375 \n",
      "Prediction :\n",
      "[[155.8002  ]\n",
      " [184.94467 ]\n",
      " [183.5018  ]\n",
      " [198.48962 ]\n",
      " [141.66345 ]\n",
      " [102.210625]\n",
      " [147.30884 ]\n",
      " [107.470985]\n",
      " [170.71796 ]\n",
      " [155.00887 ]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 17.899471282958984 \n",
      "Prediction :\n",
      "[[155.66457]\n",
      " [184.98828]\n",
      " [183.4297 ]\n",
      " [198.51572]\n",
      " [141.66173]\n",
      " [102.39494]\n",
      " [147.42601]\n",
      " [107.68823]\n",
      " [170.9345 ]\n",
      " [155.45917]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 16.609485626220703 \n",
      "Prediction :\n",
      "[[155.53574]\n",
      " [185.02892]\n",
      " [183.3608 ]\n",
      " [198.5409 ]\n",
      " [141.65855]\n",
      " [102.57013]\n",
      " [147.53911]\n",
      " [107.89806]\n",
      " [171.14027]\n",
      " [155.88887]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 15.438791275024414 \n",
      "Prediction :\n",
      "[[155.41347 ]\n",
      " [185.06676 ]\n",
      " [183.29494 ]\n",
      " [198.56525 ]\n",
      " [141.6541  ]\n",
      " [102.73663 ]\n",
      " [147.64835 ]\n",
      " [108.100784]\n",
      " [171.33588 ]\n",
      " [156.29889 ]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 14.376501083374023 \n",
      "Prediction :\n",
      "[[155.29736]\n",
      " [185.10194]\n",
      " [183.23203]\n",
      " [198.58875]\n",
      " [141.64839]\n",
      " [102.89487]\n",
      " [147.7538 ]\n",
      " [108.29664]\n",
      " [171.52176]\n",
      " [156.69014]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 13.412847518920898 \n",
      "Prediction :\n",
      "[[155.18716]\n",
      " [185.13461]\n",
      " [183.1719 ]\n",
      " [198.61147]\n",
      " [141.64156]\n",
      " [103.04521]\n",
      " [147.85564]\n",
      " [108.48587]\n",
      " [171.69836]\n",
      " [157.06343]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 12.538732528686523 \n",
      "Prediction :\n",
      "[[155.0826  ]\n",
      " [185.16492 ]\n",
      " [183.11443 ]\n",
      " [198.63342 ]\n",
      " [141.63368 ]\n",
      " [103.18805 ]\n",
      " [147.95401 ]\n",
      " [108.668755]\n",
      " [171.86612 ]\n",
      " [157.41962 ]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 11.746045112609863 \n",
      "Prediction :\n",
      "[[154.98338]\n",
      " [185.19296]\n",
      " [183.05954]\n",
      " [198.65463]\n",
      " [141.62482]\n",
      " [103.32371]\n",
      " [148.04904]\n",
      " [108.84549]\n",
      " [172.02548]\n",
      " [157.75946]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 11.027332305908203 \n",
      "Prediction :\n",
      "[[154.88927 ]\n",
      " [185.2189  ]\n",
      " [183.00706 ]\n",
      " [198.67514 ]\n",
      " [141.61507 ]\n",
      " [103.45255 ]\n",
      " [148.14084 ]\n",
      " [109.016304]\n",
      " [172.17683 ]\n",
      " [158.08371 ]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 10.37584400177002 \n",
      "Prediction :\n",
      "[[154.80002 ]\n",
      " [185.2428  ]\n",
      " [182.95691 ]\n",
      " [198.69495 ]\n",
      " [141.6045  ]\n",
      " [103.574905]\n",
      " [148.22952 ]\n",
      " [109.18145 ]\n",
      " [172.32053 ]\n",
      " [158.39304 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()  # 좌표계\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "Step_val = []\n",
    "Cost_val = []\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
    "    \n",
    "\n",
    "    Step_val.append(step)\n",
    "    Cost_val.append(cost_val)\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12,6]\n",
    "\n",
    "# Show the cost function\n",
    "plt.plot(Step_val, Cost_val)\n",
    "plt.title('cost function')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('cost')\n",
    "plt.xlim(0,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[181.05669]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score\n",
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other scores \t: \n",
      " [[155.32312]\n",
      " [185.53555]]\n"
     ]
    }
   ],
   "source": [
    "# Ask score many\n",
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
