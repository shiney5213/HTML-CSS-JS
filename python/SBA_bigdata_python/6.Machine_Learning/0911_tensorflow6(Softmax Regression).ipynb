{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Softmax Regression\n",
    "\n",
    "### Softmax Classification\n",
    "\n",
    "> Multinomial classification\n",
    "- hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import Image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('./images/1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  분류 모형\n",
    "- 이진 분류면 : sigmoid사용\n",
    "- 이진 분류 이상이면: softmax 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[10,5], [9,5], [3,2], [2,4], [11,1]]\n",
    "y_data = [[1, 0, 0], \n",
    "          [1, 0, 0], \n",
    "          [0, 1, 0], \n",
    "          [0, 1, 0],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 2])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76be2fee9d2442fb5143e35f53288f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0, \t Cost : 5.626882076263428\n",
      "Step : 200, \t Cost : 0.0699038878083229\n",
      "Step : 400, \t Cost : 0.04134545847773552\n",
      "Step : 600, \t Cost : 0.029694462195038795\n",
      "Step : 800, \t Cost : 0.02323530614376068\n",
      "Step : 1000, \t Cost : 0.019105542451143265\n",
      "Step : 1200, \t Cost : 0.0162307471036911\n",
      "Step : 1400, \t Cost : 0.014111995697021484\n",
      "Step : 1600, \t Cost : 0.012484771199524403\n",
      "Step : 1800, \t Cost : 0.01119527779519558\n",
      "Step : 2000, \t Cost : 0.010148045606911182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        # print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "        print(\"Step : {}, \\t Cost : {}\".format(step, sess.run(cost, feed_dict={X: x_data, Y: y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data : [[9.5, 5.5], [9.9, 1.5], [3.1, 2.1]] \n",
      "\n",
      "predict value : \n",
      " [[9.9236065e-01 7.6043038e-03 3.4973971e-05]\n",
      " [2.2979869e-02 5.3674785e-07 9.7701955e-01]\n",
      " [3.1210743e-02 9.6435183e-01 4.4374056e-03]] \n",
      "\n",
      "predict index : [0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Testing & One-hot encoding\n",
    "test_data = [[9.5, 5.5], \n",
    "             [9.9, 1.5], \n",
    "             [3.1, 2.1]]\n",
    "\n",
    "pred_val = sess.run(hypothesis, feed_dict={X: test_data})\n",
    "pred_idx = sess.run(tf.argmax(pred_val, 1))\n",
    "\n",
    "# print(\"predict value : \\n {} \\n\\npredict index : {}\".format(pred_val, pred_idx))\n",
    "print(\"test data : {} \\n\\npredict value : \\n {} \\n\\npredict index : {}\".format(test_data, pred_val, pred_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 15:07:01.877734  6808 deprecation.py:323] From <ipython-input-11-93abe8ccf7f2>:3: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'B']\n"
     ]
    }
   ],
   "source": [
    "# grade로 예측값 표기\n",
    "grade = ['A', 'B', 'C']\n",
    "arg_val = sess.run(tf.arg_max(pred_val, 1))\n",
    "p_grade = [ grade[val] for val in arg_val ]\n",
    "print(p_grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 복잡한 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2, 1, 1], \n",
    "          [2, 1, 3, 2], \n",
    "          [3, 1, 3, 4], \n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5], \n",
    "          [1, 2, 5, 6], \n",
    "          [1, 6, 6, 6], \n",
    "          [1, 7, 7, 7]]\n",
    "\n",
    "y_data = [[0, 0, 1], \n",
    "          [0, 0, 1], \n",
    "          [0, 0, 1], \n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0], \n",
    "          [0, 1, 0], \n",
    "          [1, 0, 0], \n",
    "          [1, 0, 0]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd53b01082324020afd3e44b7c9f6f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0, \t Cost : 5.266112804412842\n",
      "Step : 200, \t Cost : 0.5833661556243896\n",
      "Step : 400, \t Cost : 0.4858381152153015\n",
      "Step : 600, \t Cost : 0.4095403254032135\n",
      "Step : 800, \t Cost : 0.33916717767715454\n",
      "Step : 1000, \t Cost : 0.26745450496673584\n",
      "Step : 1200, \t Cost : 0.22873026132583618\n",
      "Step : 1400, \t Cost : 0.20815607905387878\n",
      "Step : 1600, \t Cost : 0.190830260515213\n",
      "Step : 1800, \t Cost : 0.1760530173778534\n",
      "Step : 2000, \t Cost : 0.16331267356872559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        # print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "        print(\"Step : {}, \\t Cost : {}\".format(step, sess.run(cost, feed_dict={X: x_data, Y: y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1132544e-02 9.7885877e-01 8.7742847e-06]] \n",
      "예측값 : [1]\n"
     ]
    }
   ],
   "source": [
    "# Testing & One-hot encoding\n",
    "a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9]]})\n",
    "print(a, '\\n예측값 :', sess.run(tf.arg_max(a, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73266745 0.24661921 0.02071326]] \n",
      "예측값 : [0]\n"
     ]
    }
   ],
   "source": [
    "b = sess.run(hypothesis, feed_dict={X: [[1, 3, 4, 3]]})\n",
    "print(b, '\\n예측값 :', sess.run(tf.arg_max(b, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6700707e-08 3.7074956e-04 9.9962926e-01]] \n",
      "예측값 : [2]\n"
     ]
    }
   ],
   "source": [
    "c = sess.run(hypothesis, feed_dict={X: [[1, 1, 0, 1]]})\n",
    "print(c, '\\n예측값 :', sess.run(tf.arg_max(c, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6700707e-08 3.7074956e-04 9.9962926e-01]] \n",
      "예측값 : [2]\n"
     ]
    }
   ],
   "source": [
    "c = sess.run(hypothesis, feed_dict={X: [[1, 1, 0, 1]]})\n",
    "print(c, '\\n예측값 :', sess.run(tf.arg_max(c, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal Classification with softmax_cross_entropy_with_logits\n",
    "- Ref : https://kr.pinterest.com/explore/animal-classification-activity/?lp=true\n",
    "- Data : https://archive.ics.uci.edu/ml/machine-learning-databases/zoo/zoo.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 16) (101, 1)\n",
      "\n",
      "x_data :\n",
      " [[1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 1. 0. 0.]]\n",
      "\n",
      "y_data :\n",
      " [[0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [3.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [1.]\n",
      " [0.]\n",
      " [3.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [5.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [3.]\n",
      " [5.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [6.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [5.]\n",
      " [4.]\n",
      " [6.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [6.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [6.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [6.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [6.]\n",
      " [3.]\n",
      " [1.]\n",
      " [5.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [5.]\n",
      " [0.]\n",
      " [6.]\n",
      " [1.]]\n",
      "\n",
      "one_hot Tensor(\"one_hot_1:0\", shape=(?, 1, 7), dtype=float32)\n",
      "\n",
      "reshape Tensor(\"Reshape_1:0\", shape=(?, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "# Predicting animal type based on various features\n",
    "xy = np.loadtxt('./data/data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "print('\\nx_data :\\n', x_data)\n",
    "print('\\ny_data :\\n', y_data)\n",
    "\n",
    "nb_classes = 7  # 0 ~ 6\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 16])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])  # 0 ~ 6\n",
    "\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"\\none_hot\", Y_one_hot)\n",
    "\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"\\nreshape\", Y_one_hot)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "logits = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                 labels=Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0, \t Loss: 5.593, \t Acc: 4.95%\n",
      "Step:   100, \t Loss: 0.600, \t Acc: 82.18%\n",
      "Step:   200, \t Loss: 0.391, \t Acc: 89.11%\n",
      "Step:   300, \t Loss: 0.288, \t Acc: 91.09%\n",
      "Step:   400, \t Loss: 0.224, \t Acc: 96.04%\n",
      "Step:   500, \t Loss: 0.182, \t Acc: 98.02%\n",
      "Step:   600, \t Loss: 0.152, \t Acc: 99.01%\n",
      "Step:   700, \t Loss: 0.131, \t Acc: 99.01%\n",
      "Step:   800, \t Loss: 0.115, \t Acc: 99.01%\n",
      "Step:   900, \t Loss: 0.102, \t Acc: 99.01%\n",
      "Step:  1000, \t Loss: 0.093, \t Acc: 99.01%\n",
      "Step:  1100, \t Loss: 0.084, \t Acc: 99.01%\n",
      "Step:  1200, \t Loss: 0.078, \t Acc: 100.00%\n",
      "Step:  1300, \t Loss: 0.072, \t Acc: 100.00%\n",
      "Step:  1400, \t Loss: 0.067, \t Acc: 100.00%\n",
      "Step:  1500, \t Loss: 0.063, \t Acc: 100.00%\n",
      "Step:  1600, \t Loss: 0.059, \t Acc: 100.00%\n",
      "Step:  1700, \t Loss: 0.056, \t Acc: 100.00%\n",
      "Step:  1800, \t Loss: 0.053, \t Acc: 100.00%\n",
      "Step:  1900, \t Loss: 0.051, \t Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2000):\n",
    "    sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 100 == 0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                             X: x_data, Y: y_data})\n",
    "        print(\"Step: {:5}, \\t Loss: {:.3f}, \\t Acc: {:.2%}\".format(\n",
    "            step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 5,  True Y : 5\n",
      "[True]  Prediction : 4,  True Y : 4\n",
      "[True]  Prediction : 4,  True Y : 4\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 5,  True Y : 5\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 5,  True Y : 5\n",
      "[True]  Prediction : 5,  True Y : 5\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 5,  True Y : 5\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 5,  True Y : 5\n",
      "[True]  Prediction : 4,  True Y : 4\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 2,  True Y : 2\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 2,  True Y : 2\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 2,  True Y : 2\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 5,  True Y : 5\n",
      "[True]  Prediction : 4,  True Y : 4\n",
      "[True]  Prediction : 2,  True Y : 2\n",
      "[True]  Prediction : 2,  True Y : 2\n",
      "[True]  Prediction : 3,  True Y : 3\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 1,  True Y : 1\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 5,  True Y : 5\n",
      "[True]  Prediction : 0,  True Y : 0\n",
      "[True]  Prediction : 6,  True Y : 6\n",
      "[True]  Prediction : 1,  True Y : 1\n"
     ]
    }
   ],
   "source": [
    "# Let's see if we can predict\n",
    "pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "\n",
    "# y_data: (N,1) = flatten => (N, ) matches pred.shape\n",
    "for p, y in zip(pred, y_data.flatten()):\n",
    "    print(\"[{}]  Prediction : {},  True Y : {}\".format(p == int(y), p, int(y)))\n",
    "    # print(\"[{}]  Prediction : {},  True Y : {}, y_data : {}\".format(p == int(y), p, int(y), y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
